## üéØ **–ù–∞–≥–ª—è–¥–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–±–ª–µ–º –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –∏ –∏—Ö –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–µ—à–µ–Ω–∏–π**

–≠—Ç–æ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º 
–≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–ª–Ω—ã–º–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è–º–∏ –Ω–∞ PyTorch.  

## üöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–∏–º–µ—Ä–æ–≤

```bash
# –∫–ª–æ–Ω–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
git clone https://github.com/yourname/DeepLearningDemonstrations.git
cd DeepLearningDemonstrations

# —Å–±–æ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
docker build -t dl-demo:latest .

# –∑–∞–ø—É—Å–∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
docker run -p 8888:8888 -v $(pwd):/workspace dl-demo:latest
```  
–î–∞–ª–µ–µ –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å –¥–µ–º–æ-–Ω–æ—É—Ç–±—É–∫–∏ –≤ Jupyter Notebook.



## üìÅ –ö–∞—Ç–∞–ª–æ–≥ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –Ω–æ—É—Ç–±—É–∫–æ–≤

| –ù–æ—É—Ç–±—É–∫ | –û–ø–∏—Å–∞–Ω–∏–µ | –°—Ç–∞—Ç—É—Å | –°–ª–æ–∂–Ω–æ—Å—Ç—å |
|---------|----------|--------|-----------|
| `01_vanishing_gradients.ipynb` | **–ó–∞—Ç—É—Ö–∞—é—â–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã**: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏, –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –ø–æ —Å–ª–æ—è–º | ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ | üü¢ –ù–∞—á–∞–ª—å–Ω—ã–π |
| `02_exploding_gradients_rnn.ipynb` | **–í–∑—Ä—ã–≤–∞—é—â–∏–µ—Å—è –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã**: –ø—Ä–æ–±–ª–µ–º–∞ –≤ RNN, gradient clipping, proper initialization | ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ | üü° –°—Ä–µ–¥–Ω–∏–π |
| `03_overfitting_demo.ipynb` | **–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ**: –∫—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è, —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è Dropout/L2, validation strategies | üîÑ –í —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ | üü¢ –ù–∞—á–∞–ª—å–Ω—ã–π |
| `04_dying_relu.ipynb` | **–£–º–∏—Ä–∞—é—â–∏–µ ReLU**: –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞, Leaky ReLU/ELU, weight initialization effects | ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ | üü° –°—Ä–µ–¥–Ω–∏–π |
| `05_class_imbalance.ipynb` | **–ù–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã**: F1-score, weighted loss, SMOTE, class weights | ‚è≥ –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ | üü° –°—Ä–µ–¥–Ω–∏–π |
| `06_bad_initialization.ipynb` | **–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤**: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ Xavier, He, normal initialization methods | ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ | üü¢ –ù–∞—á–∞–ª—å–Ω—ã–π |
| `07_data_shift_demo.ipynb` | **–°–¥–≤–∏–≥ –¥–∞–Ω–Ω—ã—Ö**: –∫–æ–≤–∞—Ä–∏–∞—Ç–∏–≤–Ω—ã–π —Å–¥–≤–∏–≥, detection methods, domain adaptation | ‚è≥ –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ | üî¥ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π |
| `08_optimizers_comparison.ipynb` | **–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã**: SGD vs Adam, learning rate schedules, loss landscapes | üîÑ –í —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ | üü° –°—Ä–µ–¥–Ω–∏–π |
| `09_batch_norm_effect.ipynb` | **Batch Normalization**: –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ, internal covariate shift | ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ | üü° –°—Ä–µ–¥–Ω–∏–π |
| `10_label_noise_robustness.ipynb` | **–ó–∞—à—É–º–ª–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏**: robust loss functions, curriculum learning | ‚è≥ –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ | üî¥ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π |

## üìÅ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Dockers

–î–ª—è –∑–∞–ø—É—Å–∫–∞ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–π –≤ Docker –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–ª–µ–¥—É—é—â—É—é –∫–æ–º–∞–Ω–¥—É:

```bash
# —Å–±–æ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
docker build -t dl-demo:latest .

# –∑–∞–ø—É—Å–∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
docker run -p 8888:8888 -v $(pwd):/workspace dl-demo:latest
```

## 